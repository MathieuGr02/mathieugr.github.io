{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can use HMMs to describe what a gene is and use that model to identify genes in the genomic sequence.\n",
    "\n",
    "A gene is a continious stretch of nucleotides in the genome that encodes a protein."
   ],
   "id": "b3c5c10067f47d54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Open reading frames\n",
    "\n",
    "A ribosome knows where to start translation due to the shine-Dalgarno sequence, which is a G and A rich sequence, upstream of the start codon. Due to this base richness, one can try to detect genes where this pattern is present.\n",
    "The space between a start and stop codon is called the open reading frame (ORF). Given 64 possible codons (base triplet), we may ask ourselves, what is the average ORF. Given the stop codon probability $P(stop) = \\frac{3}{64}$, the probability that we have a ORF of length of $l$ is given as\n",
    "\n",
    "$$\n",
    "    P((\\bar{stop}_{l-1} stop)) = \\left(  1 - \\frac{3}{64}  \\right)^{l-1}  \\frac{3}{64}\n",
    "$$\n",
    "\n",
    "The average length is then\n",
    "\n",
    "$$\n",
    "\\langle l \\rangle = \\sum_{l=1}^{\\infty} l p^{l-1} (1 - p) = \\frac{64}{3}\n",
    "$$\n",
    "\n",
    "The ORF obviously depends on the G,C and A,T content, as all the stop codons contain A. Meaning that a increase in G/C content increases our average ORF length.\n",
    "The ORF itself is not enough, as we'd have to decide the cutoff for a valid ORF length. But there are also short ORF which encode for functional peptides. Additionally there are also genes that do not encode for proteins."
   ],
   "id": "3ed0a8002fead35c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Promoter regions\n",
    "\n",
    "Upstream of the transcription start site, there exist other motifs, like the $\\sigma$ factor binding site and the Pribnow TATA box, which are regions recognized by the $\\sigma 70$ subunit polymerase. There also exist transcription terminators, which are created due to RNA internal bonding, creating a hairpin structure."
   ],
   "id": "9c1c401ed98ba35a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# HMM bacterial gene prediction (ORF prediction)",
   "id": "25d7a1f7b4c88306"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](hmm_gene.png)",
   "id": "6dc60e054afc4f8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The null block is to model everything that is not part of a gene. After that is the RBS submodule, which models the ribosomal binding site aswell as nucleotides between the RBS and the start codon. The start codon is modelled with 3 nucleotides. After the start codon, the first triplet is explicitely modeled with 3 nucleotides as it appears that this part differs from the rest of the gene. Similarly the last codon before the stop codon is modeled explicitly and 6 bases after the stop in order to capture information present around the stop codon. Inside the these parts are 3 looped codon submodels for the interior part of the gene. The reason for these submodules is to embed a realistic length distribution in the HMM instead of the geometric distribution.\n",
    "\n",
    "The 1 codon model would give the distribution $P(l + 1) = p^l (1 - p)$. On the other hand, the 3 codon model would give $P(l + 3) = \\frac{p^l (1 - p)^3 (l+1)(l+2)}{2}$"
   ],
   "id": "184f366f7a227add"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Eukaryotic\n",
    "\n",
    "Due to the presence of introns and exons, the prediction becomes more difficult, as the not all of the ORF is relevant for the encoding protein.\n",
    "\n",
    "There are different intron phases\n",
    "- Phase 0 Intron: The intron is inbetween two codons, between the end of the first and the beginning of the second\n",
    "- Phase 1 Intron: The intron which is located after the first nucleotide of a codon\n",
    "- Phase 2 Intron: The intron which is located after the second nucleotide of a codon"
   ],
   "id": "ca4c9bc653b337c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](hmm_eukaryot.png)",
   "id": "968c93bc511254f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Regulatory elements in DNA and RNA\n",
    "\n",
    "RNA synthesis is regulated by transcription factors. Experimentally, TF binding sites are identified by the ChIP-seq, which is chromatin immunoprecipitation and sequencing."
   ],
   "id": "201d6abca942c825"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](chip-seq.png)",
   "id": "8b586fda230ce496"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Using this one first has to align the read sequences with the genome and find the best alignment. That is, find the distance $d$ that maximized the correlation function\n",
    "\n",
    "$$\n",
    "C(d) = \\sum_{i = 1}^{|G|} r_+(i) r_-(i+d)\n",
    "$$\n",
    "\n",
    "Given\n",
    "- $n_i, m_i$ = Number of foreground / background reads in window $i$\n",
    "- $N, M$ = Total number of foreground / background reads in the sample\n",
    "- $\\sigma^2$ = Variance of multiplicative noise introduced during sample preperation\n",
    "- $\\mu$ = Depletion of background reads in bound regions\n",
    "- $\\rho$ = Fraction of background windows\n",
    "- $W$ = Window size\n",
    "- $R$ = Range of variation of log read density in foreground vs background in a window\n",
    "\n",
    "The probability to observe $n$ reads in a given window - given that the window could be \"bound\" or \"not bound (unbound)\" by the TF is given as\n",
    "\n",
    "$$\n",
    "P_b(n | m, N, M) = \\frac{1}{R}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_u(n | m, N, M, \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi (2 \\sigma^2 + \\frac{1}{n} + \\frac{1}{m})}} \\exp\\left( -\\frac{(\\log(\\frac{n}{N}) - \\log(\\frac{m}{M}) - \\mu)^2}{2 (2 \\sigma^2 + \\frac{1}{n} + \\frac{1}{m})} \\right)\n",
    "$$\n",
    "\n",
    "The log likelihood of the data is then given as\n",
    "\n",
    "$$\n",
    "L = \\sum_i P_{mix} (n_i | m_i, N, M, \\rho, \\mu, \\sigma) = \\sum_i \\rho P_u(n_i | m_i, N, M, \\mu, \\sigma) + (1 - \\rho) P_b(n_i | m_i, N, M)\n",
    "$$\n",
    "\n",
    "After parameter fitting, a z-score can be calculated for every window\n",
    "\n",
    "$$\n",
    "z = \\frac{\\log(\\frac{n}{N}) - \\log(\\frac{m}{M}) - \\mu}{\\sqrt{2 \\sigma^2 + \\frac{1}{n} + \\frac{1}{m}}}\n",
    "$$\n",
    "\n",
    "Then modeling the coverage per position with a mixture of gaussian peaks, for a given region we get\n",
    "\n",
    "$$\n",
    "L(C | \\vec \\pi, \\vec \\sigma, \\vec \\rho, W) = \\prod_i \\left[ \\rho_j \\frac{1}{\\sqrt{2 \\pi \\sigma^2_j}} \\exp\\left( -\\frac{(i-\\mu_j)^2}{2\\sigma_j^2} \\right) + \\left(1 - \\sum_j \\rho_j \\right) \\frac{1}{W}\\right]^{C(i)}\n",
    "$$\n",
    "\n",
    "Where $\\vec \\pi, \\vec \\sigma, \\vec \\rho$ are fitted by EM. The maximas are then possible binding sites."
   ],
   "id": "666be6ce4bc80f1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Representing binding sites\n",
    "\n",
    "The interaction between the TF and the binding site is in essence characterized by two parameters\n",
    "1. The binding energy $E$ of the interaction between TF and the binding site\n",
    "2. The concentration $c$ of the transcription factor\n",
    "\n",
    "As the TF concentration increases, the fraction $P$ of the time TF is bound to the site increases\n",
    "\n",
    "$$\n",
    "P_{bound} = \\frac{ce^{\\beta E}}{ce^{\\beta E} + K }\n",
    "$$\n",
    "\n",
    "We assume the binding energy of a sequence $s$ is an additive function of the individual bases\n",
    "\n",
    "$$\n",
    "E(s) = \\sum_{i=1}^l E_i(s_i)\n",
    "$$\n",
    "\n",
    "The probability for the site to be bound can be roughly described by the function $P_{bound}(s)$.\n",
    "Assume that the only constraint on \"functional binding sites\" is that they have some characteristic average energy $E$. Using the maximum entropy we get\n",
    "\n",
    "$$\n",
    "P(s) = \\frac{e^{\\lambda E(s)}}{\\sum_{s'}e^{\\lambda E(s')}} = \\prod_{i=1}^l \\frac{e^{\\lambda E_i(s_i)}}{\\sum_{\\alpha} e^{\\lambda E_i(\\alpha)}}\n",
    "$$\n",
    "\n",
    "Where the lagrange multiplier $\\lambda$ is chosen such that $\\sum_s E(s) P(s) = E$.\n",
    "\n",
    "We can rewrite $P(s)$ in terms of a weight matrix WM $w$.\n",
    "\n",
    "$$\n",
    "P(s) = \\prod_{i=1}^l P_i(s_i) = \\prod_{i=1}^l w_{s_i}^i\n",
    "$$\n",
    "\n",
    "The probability that a binding site for the TF will have a sequence $s$ is given by\n",
    "\n",
    "$$\n",
    "P(s|w) = \\prod_{i=1}^l w_{s_i}^i\n",
    "$$\n",
    "\n",
    "These weights can be estimated by counting where $\\alpha$ is a pseudo count.\n",
    "\n",
    "$$\n",
    "w_b^i = \\frac{n_b^i + \\alpha_b^i}{\\sum_b (n_b^i + \\alpha_b^i)}\n",
    "$$\n",
    "\n",
    "The question is, how do we set the pseudo count.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    P(S | w)\n",
    "    &=\n",
    "    \\prod_{s \\in S} P(s | w) \\\\\n",
    "    &=\n",
    "    \\prod_{s \\in S} [\\prod_{i=1}^l w^i_{s_i}] \\\\\n",
    "    &=\n",
    "    \\prod_{i=1}^l  [\\prod_{s \\in S} w^i_{s_i}] \\\\\n",
    "    &=\n",
    "    \\prod_{i=1}^l [\\prod_{\\alpha} (w_{\\alpha}^i)^{n_{\\alpha}^i}]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "To calculate the posterior $P(w | S)$ we need the prior, for this we use the familiy of dirichlet priors $P(w)dw = \\frac{\\Gamma (4 \\gamma)}{[\\Gamma(\\gamma)]^4} \\prod_{\\alpha} (w_{\\alpha}^{\\gamma - 1})dw$.\n",
    "For $\\gamma = 1$ we have a uniform prior. For $\\gamma < 1$ more weight is on the corners and edges of the simplex, the distribution is heavily biased to one or two bases. For $\\gamma > 1$ more weight is on the middle of the simplex, the distribution of all bases are equal.\n",
    "\n",
    "Given this prior, we can calculate the posterior as $P(w | S) = \\frac{P(S|w)P(w)}{P(S)}$. This is the probability that all sequences in $S$ come from $w$.\n",
    "\n",
    "The information score of the WM is a measure of the specificity of the binding factor\n",
    "\n",
    "$$\n",
    "I = \\sum_{i,b} f_b^i \\log(\\frac{f_b^i}{p_b})\n",
    "$$\n",
    "\n",
    "Where $f_b^i = \\frac{n_b^i}{\\sum_b n_b^i}$ and $p_b$ is the background frequency of nucleotide $i$.\n",
    "\n",
    "To compute the likelihood of a sequence given the WM is just the multiplication of the prob of the nucleotides at their respective position.\n",
    "\n",
    "$$\n",
    "P(s[i..i+\\omega - 1] | \\vec w) = \\prod_{j=1}^{\\omega} w_{s[i+j]}^j\n",
    "$$\n",
    "\n",
    "Where $\\omega$ is the length of $\\vec w$."
   ],
   "id": "bbf78b589a3e13df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Finding multiple sites\n",
    "\n",
    "Given we have the WM for two TF sites and the model of the background sequence $B$.\n",
    "\n",
    "A parse is one way of placing WM and background regions over a sequence. The likelihood of a given parse for each region is then\n",
    "\n",
    "$$\n",
    "P(s[i..i+\\omega - 1]|\\vec w) = \\prod_{j=1}^{\\omega} w_{s_{i+j}}^j\n",
    "$$\n",
    "\n",
    "Where $\\vec w$ is either the WM corresponding to the TF bound at $i$ or the background, and $\\omega$ the length of the WM.\n",
    "\n",
    "The total likelihood of the sequence, summed over all possible parses, represents the partition function $Z$.\n",
    "\n",
    "$$\n",
    "Z(1, i) = \\sum_{j=1}^m Z(1, i - \\omega_j) P(s[i-\\omega_j + 1 .. i]| \\vec w^j)\n",
    "$$\n",
    "\n",
    "This is a summation over all $m$ weight matrices of the contribution of parses neding with a given weight matrix at position $i$. The posterior prob to have a site for $TF_i$ starting at position $i$ is then\n",
    "\n",
    "$$\n",
    "P(TF_i \\ at \\ j) = \\frac{Z(1, i - 1)P(s[i..i+\\omega_i - 1 | \\vec w^i])Z(i + \\omega_i, L)}{Z(1, L)}\n",
    "$$"
   ],
   "id": "8db37e1de442d5cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](parses.png)",
   "id": "7c98bf0d91129bae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Inferring novel binding specificities\n",
    "\n",
    "Imagine we've identified regions that are bound by a given TF whose specificity we do not know. We would like to find the binding specificity of the TF, find the WM from this set of binding sites.\n",
    "\n",
    "Using the gibbs sampling algorithm for inferring binding specificity, we start with windows placed randomly, one in each sequence.\n",
    "\n",
    "- At each iteration\n",
    "    - Remove one window,\n",
    "    - Use the others to infer WM\n",
    "    - At each position in sequence $i$ calculate the probability that the subsequence starting at that position was generated from the WM\n",
    "    - Sample one window according to these probabilities\n",
    "\n",
    "\n",
    "Each way of placing a window of length $L$ in each of the $n$ upstream regions represents a state $x$, with an associated probability $P(x)$. $P(x)$ is proportional to the likelihood that all subsequences enclosed by the windows are generated using the same WM.\n",
    "To find states with high probability, sample $P(x)$ using a markov chain.\n",
    "1. Given state $x$, state $y$ is proposed with probability $P(y|x)$, such that $P(y|x) = P(x|y)$\n",
    "2. State $y$ is accepted with probability $min(1, P(y)/P(x))$\n",
    "\n",
    "For the MEME algorithm, we start with a guess for a weight matrix and for the probability of occurence of binding sites.\n",
    "\n",
    "At each iteration, we use the current WM and prior probability for binding sites to calculate the probability at each position in every sequence that there is a binding site starting at that position. We then update the WM and prior probability of sites.\n",
    "\n",
    "The posterior of a site starting at position $j$ is\n",
    "\n",
    "$$\n",
    "P(site \\ at \\ j) = \\frac{\\pi_t P(s[j..j+\\omega - 1] | \\vec w)}{\\pi_t P(s[j..j + \\omega - 1] | \\vec w) + (1 - \\pi_t) P(s[j..j+\\omega - 1]|\\vec B)}\n",
    "$$\n",
    "\n",
    "We update the prior with\n",
    "\n",
    "$$\n",
    "\\pi_{t+1} = \\frac{\\sum_j P(site \\ at \\ j)}{L}\n",
    "$$\n",
    "\n",
    "And update the WM\n",
    "\n",
    "$$\n",
    "\\left. w_{\\alpha}^{k}\\right|_{t+1}= \\frac{\\sum_{j} P(site \\ at \\ j) \\delta(s[j + k], \\alpha)}{\\sum_j P(site \\ at \\ j)}\n",
    "$$"
   ],
   "id": "eaf821ceeecf29b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The discovery of regulatory sites is done by\n",
    "\n",
    "1. Collect sets of sequences that are thought to contain binding sites for a common regulatory factor. Then search overrepresented short sequence motifs.\n",
    "2. Phylogenetic footprinting: Create multiple alignments of orthologous intergenic sequences and identify sequence segments more conserved than \"average\".\n",
    "\n",
    "The nucleotides in one column are not independent samples of the WM, but are phylogenetically related. The probability of an alignment column is $P(S | T, w)$. It is the probability of the bases at the leaves of a given tree and the limit frequency $w$ is the product over the transition probabilities along each of the branches, summed over the possible bases at the internal nodes.\n",
    "\n",
    "$$\n",
    "P(S | T, w) = \\sum_{x,y,z} w_x P(y | x, t_1) P(g|x, t_2) P(g|y, t_3) P(z | y, t_4) P(g|z, t_5) P(a|a, t_6)\n",
    "$$"
   ],
   "id": "45eccfdd3aeb5680"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ahab scoring model\n",
    "\n",
    "Rather than assuming that we expect binding sites to be uniformly distributed across the sequence, Ahab assumes that different regions upstream have different prior probabilities of containing binding sites. Thus the likelihood of a sequence segment given a WM depends not only on the sequence, but also on the prior probability of a site for the TF in that genomic region\n",
    "\n",
    "$$\n",
    "P(s[i..i+\\omega - 1] | \\vec w) = \\pi \\prod_{j=1}^{\\omega} w_{s[i+j]}^j\n",
    "$$\n",
    "\n",
    "Ahab determines the set of priors for all the $m$ WM that maximize the partition function for a given region of the upstream sequence.\n",
    "\n",
    "$$\n",
    "Ahab \\ score = \\frac{Z(1, L| \\{\\vec w\\})}{Z(1, L | \\vec w_B)}\n",
    "$$"
   ],
   "id": "4534431ecdd7dab7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
