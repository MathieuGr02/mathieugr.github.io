{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: Neural Encoder Decoder\n",
    "layout: collection\n",
    "permalink: /Machine-Learning/Neural-Encoder-Decoder\n",
    "collection: Machine-Learning\n",
    "entries_layout: grid\n",
    "mathjax: true\n",
    "toc: true\n",
    "categories:\n",
    "  - study\n",
    "tags:\n",
    "  - mathematics\n",
    "  - statistics\n",
    "  - machine-learning \n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ba1a18f7916e71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Non-Linear Latent variable\n",
    "\n",
    "In a non-linear latent variable model out likelihood is gaussian disributed with a non-linear transformed mean vector \n",
    "\n",
    "$$\n",
    "\\mathbf{\\mu} = \\mathbf{f} (\\mathbf{z} , \\phi ) \n",
    "$$\n",
    "\n",
    "The prior and likelihood then look like\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathbb{P}(\\mathbf{z}) &= \\mathcal{N}(0, I) \\\\\n",
    "     \\mathbb{P}(\\mathbf{x} | \\mathbf{z}, \\phi  ) &= \\mathcal{N}(f(\\mathbf{z}, \\phi ), \\sigma^2 I ) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Given an observation $ \\mathbf{x}  $ we would then like to understand which hidenn latent variables we're responsible for the creation of $ \\mathbf{x}  $, this is given by the posterior:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\mathbf{z} | \\mathbf{x} ) = \\frac{\\mathbb{P}(\\mathbf{x} | \\mathbf{z} )\\mathbb{P}(\\mathbf{z})}{\\mathbb{P}(\\mathbf{x} )}  \n",
    "$$\n",
    "\n",
    "There exist no closed form form the posterior as the mean is a non-linear function. We can also not evaluate the evidence.\n",
    "\n",
    "But sampling from this model is easy, we just draw a latent variable from the prior, pass it through our non-linear function to get the mean and then draw $\\mathbb{x}$ with this mean from the likelihood.\n",
    "\n",
    "Looking at the marginal likelihood of the evidence\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathbb{P}(\\mathbf{x} | \\phi ) \n",
    "    &= \n",
    "    \\int \\mathbb{P}(\\mathbf{x}, \\mathbf{z} | \\phi ) d \\mathbf{z}  \\\\\n",
    "    &=\n",
    "    \\int \\mathbb{P}(\\mathbf{x} | \\mathbf{z}, \\phi  ) \\mathbb{P}(\\mathbf{z} ) d \\mathbf{z} \\\\\n",
    "    &=\n",
    "    \\int \\mathcal{N}(\\mathbf{f}(\\mathbf{z}, \\phi ), \\sigma^2 I ) \\mathcal{N}(0, I) d \\mathbf{z}     \n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\n",
    "Because $f$ is thus an arbitrary function, this integral doesn't have a closed form, but we can approximate it using the jensens inequality.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\log[\\mathbb{P}(\\mathbf{x} | \\phi ) ] \n",
    "    &= \n",
    "    \\log \\left[\\int \\mathbb{P}(\\mathbf{x}, \\mathbf{z} | \\phi ) d \\mathbf{z}  \\right] \\\\\n",
    "    &=\n",
    "    \\log \\left[\\int q(\\mathbf{z})  \\frac{\\mathbb{P}(\\mathbf{x}, \\mathbf{z} | \\phi )}{q(\\mathbf{z} )}  d \\mathbf{z}  \\right] \\\\\n",
    "    &\\geq\n",
    "    \\int q(\\mathbf{z})  \\log \\left[ \\frac{\\mathbb{P}(\\mathbf{x}, \\mathbf{z} | \\phi )}{q(\\mathbf{z} )}\\right]  d \\mathbf{z}   \\\\\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\n",
    "This holds true for any distribution $q$. This lower bound is called the evidence lower bound (ELBO). \n",
    "We assume that the distribution $q$ has some parameters $ \\mathbf{\\theta}  $. \n",
    "The ELBO then is given as \n",
    "\n",
    "$$\n",
    "ELBO[\\mathbf{\\theta}, \\phi ] = \\int q(\\mathbf{z}) \\log \\left[ \\frac{\\mathbb{P}(\\mathbf{x}, \\mathbf{z} | \\phi  ) }{q(\\mathbf{z} | \\mathbf{\\theta}  )}  \\right] d \\mathbf{z} \n",
    "$$\n",
    "\n",
    "Becuase we want the tighest lower bound. i.e. approximate our evidence as best as possible, we would thus like to maximize the ELBO as a function of $ \\mathbf{\\theta}  $ and $\\phi$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    ELBO[\\mathbf{\\theta}, \\phi]\n",
    "    &=\n",
    "    \\int q(\\mathbf{z}, \\mathbf{\\theta}) \\log \\left[ \\frac{\\mathbb{P}(\\mathbf{x}, \\mathbf{z} | \\phi)}{q(\\mathbf{z}| \\mathbf{\\theta})} \\right] d \\mathbf{z} \\\\\n",
    "    &=\n",
    "    \\int q(\\mathbf{z}, \\mathbf{\\theta}) \\log \\left[ \\frac{\\mathbb{P}(\\mathbf{z} | \\mathbf{x}, \\phi) \\mathbb{P}(\\mathbf{x} | \\phi)}{q(\\mathbf{z}| \\mathbf{\\theta})} \\right] d \\mathbf{z} \\\\\n",
    "    &=\n",
    "    \\int q(\\mathbf{z} | \\mathbf{\\theta}) \\log [\\mathbb{P}(\\mathbf{x} | \\phi)] d \\mathbf{z} + \\int q(\\mathbf{z} | \\mathbf{\\theta}) \\log \\left[ \\frac{\\mathbb{P}(\\mathbf{z} | \\mathbf{x}, \\phi)}{q(\\mathbf{z}|\\mathbf{\\theta})} \\right] d \\mathbf{z} \\\\\n",
    "    &=\n",
    "    \\log [\\mathbb{P}(\\mathbf{x} | \\phi)] + \\int q(\\mathbf{z} | \\mathbf{\\theta}) \\log \\left[ \\frac{\\mathbb{P}(\\mathbf{z} | \\mathbf{x}, \\phi)}{q(\\mathbf{z}|\\mathbf{\\theta})} \\right] d \\mathbf{z} \\\\\n",
    "    &=\n",
    "    \\log [\\mathbb{P}(\\mathbf{x} | \\phi)] - \\mathbb{KL}[q(\\mathbf{z}|\\mathbf{\\theta}) || \\mathbb{P}(\\mathbf{z}|\\mathbf{x}, \\phi)]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This is maximized when we have $q(\\mathbf{z}|\\mathbf{\\theta}) = \\mathbb{P}(\\mathbf{z}|\\mathbf{x}, \\phi) $. \n",
    "We can also write a different expression for the ELBO\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    ELBO[\\mathbf{\\theta}, \\phi] \n",
    "    &= \n",
    "    \\int q(\\mathbf{z} |\\mathbf{\\theta} ) \\log \\left[ \\frac{\\mathbb{P}(\\mathbf{x}, \\mathbf{z} | \\phi)}{q(\\mathbf{z}|\\mathbf{\\theta})} \\right] d \\mathbf{z} \\\\\n",
    "    &=\n",
    "    \\int q(\\mathbf{z} |\\mathbf{\\theta} ) \\log \\left[ \\frac{\\mathbb{P}(\\mathbf{x} | \\mathbf{z}, \\phi) \\mathbb{P}(\\mathbf{z})}{q(\\mathbf{z}|\\mathbf{\\theta})} \\right] d \\mathbf{z} \\\\\n",
    "    &=\n",
    "    \\int q(\\mathbf{z} | \\mathbf{\\theta}) \\log [\\mathbb{P}(\\mathbf{x} | \\mathbf{z}, \\phi)] d \\mathbf{z} + \\int q(\\mathbf{z}|\\mathbf{\\theta}) \\log \\left[ \\frac{\\mathbb{P}(\\mathbf{z})}{q(\\mathbf{z}|\\mathbf{\\theta})} \\right] d \\mathbf{z} \\\\\n",
    "    &=\n",
    "    \\int q(\\mathbf{z} | \\mathbf{\\theta}) \\log [\\mathbb{P}(\\mathbf{x} | \\mathbf{z}, \\phi)] d \\mathbf{z} - \\mathbb{KL}(q(\\mathbf{z}|\\mathbf{\\theta}) || \\mathbb{P}(\\mathbf{z}))\n",
    "    \n",
    "\\end{align*}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c5d254ab81aa1cc"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2cabb6183d57ba23"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59b13748c6ff283e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
