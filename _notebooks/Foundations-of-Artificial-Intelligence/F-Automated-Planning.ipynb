{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "classification\n",
    "\n",
    "- static\n",
    "- determenistic\n",
    "- fully observable\n",
    "- discrete\n",
    "- single agent\n",
    "- general"
   ],
   "id": "c0f30dcfe2b5ef1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Automated planning\n",
    "\n",
    "Is a way of finding plans (sequences of actions) that lead from an initial state to a goal state.\n",
    "Here we look at classic planning\n",
    "- General approach to finding solutions for state space search problems\n",
    "- Classic = static, deterministic, fully observable\n",
    "- Variants: Probalistic planning, planning under partial observability, online planning, etc.\n",
    "\n",
    "Given\n",
    "- A state space description in terms of suitable problem description language (planning formalism)\n",
    "\n",
    "Required\n",
    "- A plan, i.e. a solution for the described state space (sequence of actions from initial state to goal state)\n",
    "- Or proof that no plan exists\n",
    "\n",
    "Distinguish between\n",
    "- Optimal planning: Guarantee that the returned plans are optimal, i.e., have minimal overall cost\n",
    "- Suboptimal planning (satisficing): Suboptimal plans are allowed"
   ],
   "id": "80da667fedd5de24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Four planning\n",
    "\n",
    "A description language for state spaces (planning tasks) is called a planning formalism."
   ],
   "id": "4796a22bb2cd11ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# STRIPS\n",
    "\n",
    "- It is the most simple common planning formalism.\n",
    "- State variables are binary (true or false)\n",
    "- States $s$ (based on a given set of state variables $V$) can be represented in two equivalent ways\n",
    "    - As assignments $s: V \\rightarrow \\{\\mathbf{T}, \\mathbf{F}\\}$\n",
    "    - As sets $s \\subseteq V$ where $s$ encodes the set of state variables that are true in $s$.\n",
    "- Goals and preconditions of actions are given as sets of variables that must be true (values of other variables do not matter)\n",
    "- Effects of actions are given as sets of variables that are set to true and set to false, respectively\n",
    "\n",
    "## Definition\n",
    "\n",
    "A STRIPS planning task is a 4 tuple $\\prod = \\langle V, I, G, A \\rangle$ with\n",
    "- $V$: Finite set of state variables\n",
    "- $I \\subseteq V$: The initial state\n",
    "- $G \\subseteq V$: The set of goals\n",
    "- $A$: Finite set of actions where for all actions $a \\in A$, the following is defined:\n",
    "    - $pre(a) \\subseteq V$: The preconditions of $a$\n",
    "    - $add(a) \\subseteq V$: The add effects of $a$\n",
    "    - $del(a) \\subseteq V$: The delete effects of $a$\n",
    "    - $cost(a) \\in \\mathbb{N}_0$: The cost of $a$\n",
    "\n",
    "Given thr STRIPS planning task. Then $\\prod$ induces the state space $\\mathcal{S}(\\prod) = \\langle S, A, cost, T, s_I, S_G \\rangle$:\n",
    "- Set of states $S = 2^V$\n",
    "- Actions: actions $A$ as defined in $\\prod$\n",
    "- Action costs: $cost$ as defined in $\\prod$\n",
    "- Transitions: $s \\xrightarrow[]{a} s'$ for states $s,s' \\in S$ and action $a \\in A$ iff\n",
    "    - $pre(a) \\subseteq s$ (precondition satisfied)\n",
    "    - $s' = (s \\textbackslash del(a)) \\cup add(a)$ (effects are applied)\n",
    "- Initial state: $s_I = I$\n",
    "- Goal state: $s \\in S_G$ for state $s$ iff $G \\subseteq s$ (goals reached)"
   ],
   "id": "53b9ee51015cb73d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ADL\n",
    "\n",
    "Like STRIPS, ADL uses propositional variables (true / false) as state variables. Preconditions of actions and goal are arbitrary logic formulas (action applicable / goal reached in states that satisfy the formula). In Addition to STRIPS effects, there are conditional effects: variable $v$ is only set to true / false if a given logical formula is true in the current state.\n",
    "\n",
    "# SAS+\n",
    "\n",
    "Very similair to STRIPS: state variables not necessarily binary, but with given finite domain. States are assignments to these variables. Preconditions and goals given as partial assignments. Effects are assignments to subset of variables.\n",
    "\n",
    "# PDDL\n",
    "\n",
    "Is standard language used in practice to describe planning tasks. Descriptions in predicate logic instead of propositional logic. Other features lke numeric variables and derived variables (axioms) for defining complex logical conditions (formulas that are automatically evaluated in every state and can, e.g. be used in preconditions). There exist defined PDDL fragments for STRIPS and ADL: many planners only support the STRIPS fragment."
   ],
   "id": "e06ec6e4d3d33d66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Plannning heuristics\n",
    "\n",
    "A STRIPS heuristic can be for examples the number of goals not yet satisfied\n",
    "\n",
    "$$\n",
    "h(s) = |G \\textbackslash s|\n",
    "$$\n",
    "\n",
    "The drawbacks of STRIPS heuristics is that they are rather uninformed. For state $s$, if there is no applicable action $a$ in $s$ such that applying $a$ in $s$ satisfies strictly more (or fewer) goals, then all successor states have the same heuristic value as $s$. Ignores almost the whole task structure. The heuristic values do not depends on the actions."
   ],
   "id": "98e66238b7cec892"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Delete Relaxation\n",
    "\n",
    "In STRIPS planning tasks, good and bad effects are easy to distinguish. Add effects are useful and delete effects are always harmful.\n",
    "\n",
    "The relaxation $a^+$ of STRIPS action $a$ is the action with\n",
    "- $pre(a^+) = pre(a)$\n",
    "- $add(a^+) = add(a)$\n",
    "- $cost(a^+) = cost(a)$\n",
    "- $del(a^+) = \\emptyset$\n",
    "\n",
    "The relaxation $\\prod^+$ of STRIPS plannig task $\\prod = \\langle V, I, G, A \\rangle$ is the task $\\prod^+ = \\langle V, I, G, \\{a^+  | a \\in A\\} \\rangle$\n",
    "\n",
    "STRIPS planning tasks without delete effects are called relaxed planning tasks or delete-free planning tasks. Plans for relaxed planning tasks are called relaxed plans. If $\\prod$ is a STRIPS planning task and $\\pi^+$ is a plan for $\\prod^+$ then $\\pi^+$ is called relaxed plan for $\\prod$."
   ],
   "id": "d3547be8d6001e2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Optimal relaxation heuristic $h^+$\n",
    "\n",
    "Let $\\prod$ be a STRIPS planning task with the relaxation $\\prod^+ = \\langle V, I, G, A^+ \\rangle$. The optimal relaxation heuristic $h^+$ for $\\prod$ maps each state $s$ to the cost of an optimal plan for the planning task $\\langle V, s, G, A^+ \\rangle$.\n",
    "\n",
    "For general STRIPS planning tasks, $h^+$ is an admissible and consistent heuristic. It is easy to solve delete-free planning tasks suboptimally. Optimal solution is NP-hard."
   ],
   "id": "be71606d8feefbfc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Relaxed planning graphs\n",
    "\n",
    "Relaxed planning graphs represent which variables in $\\prod^+$ can be reached and how. Graphs with variable layers $V^i$ and action layers $A^i$\n",
    "- Variable layer $V^0$ contains the variable vertex $v^0$ for all $v \\in I$.\n",
    "- Action layer $A^{i+1}$ contains the action vertex $a^{i+1}$ for action $a$ if $V^i$ contains the vertex $v^i$ for all $v \\in pre(a)$.\n",
    "- Variable layer $V^{i+1}$ contains the variable vertex $v^{i+1}$ if previous variable layer contains $v^i$ or previous action layer contains $a^{i+1}$ with $v \\in add(a)$\n",
    "- A goal vertex $g$ if $v^n \\in V^n$ for all $v \\in G$, where $n$ is the last layer\n",
    "- Graph can be constructed for arbitrary many layers but stabilizes after a bounded number of layers $\\rightarrow V^{i+1} = V^i$ and $A^{i+1} = A^i$\n",
    "- Directed edges\n",
    "    - from $v^i$ to $a^{i+1}$ if $v \\in pre(a)$\n",
    "    - from $a^i$ to $v^{i}$ if $v \\in add(a)$\n",
    "    - from $v^i$ to $v^{i+1}$\n",
    "    - from $v^n$ to $g$ if $v \\in G$\n",
    "\n",
    "## Heuristic Values from relaxed planning graph\n",
    "\n",
    "- function generic-rpg-heuristic($\\langle V, I, G, A\\rangle, s$):\n",
    "    - $\\prod^+ = \\langle V, s, G, A^+ \\rangle$\n",
    "    - for $k \\in \\{0,1,2,...\\}$:\n",
    "        - rpg = $RPG_k(\\prod^+)$\n",
    "        - if rpg contains a goal node\n",
    "            - Annotate nodes of rpg\n",
    "            - if termination criterion is true:\n",
    "                - return heuristic value from annotations\n",
    "        - else if graph is stabilized\n",
    "            - return $\\infty$"
   ],
   "id": "637e0ece7d37e6e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Maximum and Additive heuristics\n",
    "\n",
    "$h^{max}$ and $h^{add}$ are the simplest RPG heuristics. Vertex annotatoins are numerical values. The vertex values estimate the cost\n",
    "- to make a given variable true\n",
    "- to reach and apply a given action\n",
    "- to reach the goal\n",
    "\n",
    "**cost of variable vertices**\n",
    "- 0 in layer 0\n",
    "- otherwise minimum of the costs of predecessor vertices\n",
    "\n",
    "**costs of action and goal vertices**\n",
    "- maximum ($h^{max}$) or sum ($h^{add}$) of predecessor vertex costs, for action vertices $a^i$, also add cost(a).\n",
    "\n",
    "**termination criterion**\n",
    "- Stability: terminate if $V^i = V^{i-1}$ and costs of all vertices in $V^i$ equal corresponding vertex costs in $V^{i-1}$\n",
    "\n",
    "**heuristic value**\n",
    "- value of goal vertex\n",
    "\n",
    "**variable vertices**\n",
    "- choose cheapest way of reaching the variable\n",
    "\n",
    "**action/goal vertices**\n",
    "- $h^{max}$ is optimistic: assumption: when reaching the most expensive precondition variable, we can reach the other precondition variables in parallel.\n",
    "- $h^{add}$ is pessimistic: assumption: all precondition variables must be reached completely independently of each other (hence summation costs).\n",
    "\n",
    "comparison\n",
    "- both are safe and goal-aware\n",
    "- $h^{max}$ is admissible and consistent; $h^{add}$ is neither $\\rightarrow h^{add}$ is not suited for optimal planning\n",
    "- However, $h^{add}$ is usually more informative than $h^{max}$. Greedy best-first-search with $h^{add}$ is a decent algorithm\n",
    "- Apart from not being admissible, $h^{add}$ often vastly overetimates the actual costs because positive synergies between subgoals are not recognized."
   ],
   "id": "425a0fb0e2514fef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# FF Heuristic\n",
    "\n",
    "Identical to $h^{add}$, but additional steps at the end:\n",
    "- Mark goal vertex\n",
    "- Apply the following marking rules until nothing more to do:\n",
    "    - Marked action or goal vertex?\n",
    "        - mark all predecessors\n",
    "    -  Marked variable vertex $v^i$ in layer $i \\geq 1$?\n",
    "        - mark one predecessor with minimal $h^{add}$ value (tie breaking: prefer variable vertices; otherwise arbitrary)\n",
    "\n",
    "**Heuristic value**\n",
    "- The actions corresponding to the marked action vertices build a relaxed plan\n",
    "- The cost of this plan is the heuristic value.\n",
    "\n",
    "- Like $h^{add}$, $h^{FF}$ is safe and goal-aware.\n",
    "- Approximation of $h^+$ which is always at least as good as $h^{add}$\n",
    "- Usually significantly better\n",
    "- Can be computed in almost linear time $(O(n \\log n))$ in the size of the description of the planning task\n",
    "- Computation of heuristic value depends on tie-breaking of marking rules ($h^{FF} not well defined$)\n",
    "- one of the most successful planning heuristics\n",
    "\n",
    "Let $s$ be a state in the STRIPS planning task $\\langle V, I, G, A \\rangle$.\n",
    "\n",
    "Then\n",
    "- $h^{max}(s) \\leq h^+(s) \\leq h^*(s)$\n",
    "- $h^{max}(s) \\leq h^+(s) \\leq h^{FF}(s) \\leq h^{add}(s)$\n",
    "- $h^*$ and $h^{FF}$ are incomparable\n",
    "- $h^*$ and $h^{add}$ are incomparable\n",
    "\n",
    "For non-admissible heuristics, it is generally neither good nor bad to compute higher values than other heuristic.\n",
    "For relaxation heuristics, the objective is to approximate $h^+$ as closely as possible."
   ],
   "id": "17f211df4265a949"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SAS$^+$\n",
    "\n",
    "The difference between STRIPS and SAS$^+$ is that the state variables $v$ are not binary, but with finite domain $dom(v)$. Accordingly, preconditions, effects and goals are specified as partial assignments. Everything else is equal to STRIPS.\n",
    "\n",
    "A SAS$^+$ planning task is a 5-tuple $\\prod = \\langle V, dom, I, G, A \\rangle$ with the following components\n",
    "- $V$: finite set of state variables\n",
    "- $dom$: domain; $dom(v)$ finite and non-empty for all $v \\in V$. states: Total assignments for $V$ according to $dom$.\n",
    "- $I$: The initial state (state = total assignment)\n",
    "- $G$: Goals (partial assignment)\n",
    "- $A$: finite set of actions $a$ with\n",
    "    - $pre(a)$: Its preconditions (partial assignment)\n",
    "    - $eff(a)$: Its effects (partial assignment)\n",
    "    - $cost(a) \\in \\mathbb{N}_0$: Its cost\n",
    "\n",
    "\n",
    "Let $\\prod = \\langle V, dom, I, G, A \\rangle$ be a SAS$^+$ planning task. Then $\\prod$ induces the state space $\\mathcal{S}(\\prod) = \\langle S, A, cost, T, s_I, S_G \\rangle$:\n",
    "- Set of states: total assignments of $V$ according to $dom$\n",
    "- Actions: actions $A$ defined in $\\prod$\n",
    "- Action costs: cost as defined in $\\prod$\n",
    "- Transitions: $s \\xrightarrow[]{a} s'$ for states $s,s'$ and action $a$ iff\n",
    "    - $pre(a)$ agrees with $s$ (precondition satisfied)\n",
    "    - $s'$ agrees with $eff(a)$ for all variables mentioned in $eff$, agrees with $s$ for all other variables (effects are applied)\n",
    "- initial state: $s_I = I$\n",
    "- goal state: $s \\in S_G$ for state $s$ iff $G$ agrees with $s$"
   ],
   "id": "23efa572657f38e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Abstraction\n",
    "\n",
    "State space abstraction drop distinctions between certain states, but preserve the state space behaviour as well as possible.\n",
    "- An abstraction of a state space $\\mathcal{S}$ is defined by an abstraction function $\\alpha$ that determines which states can be distinguished in the abstraction.\n",
    "- Based on $\\mathcal{S}$ and $\\alpha$, we compute the abstract state space $\\mathcal{S}^{alpha}$ which is \"similair\" to $\\mathcal{S}$ but smaller.\n",
    "- Use optimal solution cost in $\\mathcal{S}^{\\alpha}$ as heuristic.\n",
    "\n",
    "Let $\\mathcal{S} = \\langle S, A, cost, T, s_I, S_G \\rangle$ be a state space, and let $\\alpha:S \\rightarrow S'$ be a surjective function. The abstraction of $\\mathcal{S}$ induced by $\\alpha$, denoted as $\\mathcal{S}^{\\alpha}$, is the state space $\\mathcal{S}^{\\alpha} = \\langle S', A, cost, T', s_I', S_G' \\rangle$ with\n",
    "- $T' = \\{\\langle \\alpha(s), a, \\alpha(t) \\rangle | \\langle  s, a, t \\rangle \\in T \\}$\n",
    "- $s_I' = \\alpha(s_I)$\n",
    "- $S_G' = \\{\\alpha(s) | s \\in S_G\\}$"
   ],
   "id": "64c5937c2a4d705b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Abstraction Heuristic\n",
    "\n",
    "Given an abstraction function $\\alpha$ for a state space $\\mathcal{S}$, use abstract solution cost (solution cost of $\\alpha(s)$ in $\\mathcal{S}^{\\alpha}$) as heuristic for concrete solution cost (solution cost of $s$ in $\\mathcal{S}$).\n",
    "\n",
    "The abstract heuristic for abstraction $\\alpha$ maps each state $s$ to its abstract solution cost\n",
    "\n",
    "$$\n",
    "h^{\\alpha}(s) = h^*_{\\mathcal{S}^{\\alpha}}(\\alpha(s))\n",
    "$$\n",
    "\n",
    "where $h^*_{\\mathcal{S}^{\\alpha}}$ is the perfect heuristic in $\\mathcal{S}^{\\alpha}$.\n",
    "\n",
    "- Every abstraction heuristic is admissible and consistent.\n",
    "- The choice of the abstraction function $\\alpha$ is very important.\n",
    "    - Every $\\alpha$ yields an admissible and consistent heuristic.\n",
    "    - But most $\\alpha$ lead to poor heuristics\n",
    "- An effective $\\alpha$ must yield an informative heuristic as well as being efficiently computable"
   ],
   "id": "3b675ea0ffa27bc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pattern Databases\n",
    "\n",
    "The most common abstraction heuristics are pattern database heuristics.\n",
    "\n",
    "A PDB heuristic for a planning task is an abstraction heuristic where\n",
    "- some aspects (= state variables) of the task are preserved with perfect precision while\n",
    "- all other aspects are not preserved at all.\n",
    "\n",
    "formalized as projections to a pattern $P \\subseteq V$:\n",
    "\n",
    "$$\n",
    "\\pi_P(s) = \\{v \\mapsto s(v) | v \\in P\\}\n",
    "$$\n",
    "\n",
    "Let $P$ be a subset of the variables of a planning task. The abstraction heuristic induced by the projection $\\pi_P$ on $P$ is called pattern database heuristic (PDB heuristic) with pattern $P$."
   ],
   "id": "9ba2379d9b482b24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
