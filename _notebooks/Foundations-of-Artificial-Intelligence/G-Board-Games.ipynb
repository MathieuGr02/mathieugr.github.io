{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Board Games\n",
    "\n",
    "The current situation is representable by finite set of positions. There is a finite set of moves players can play. The effects of actions are deterministic. The game ends when a terminal position is reached. The terminal position is reached after a finite number of steps. Terminal positions yield a utility. No randomness, no hidden information.\n",
    "\n",
    "For now we consider a two players called MAX and MIN. Both observe the entire position. It is the turn of exactly one player in each non-terminal position. Utility for MAX is opposite of utility for MIN. MAX aims to maximize utility, MIN aims to minimize utility.\n",
    "\n",
    "## Classification\n",
    "- Static\n",
    "- Deterministic\n",
    "- Fully observable\n",
    "- Discrete\n",
    "- Multi agent (adversarial)\n",
    "- Problem specific\n",
    "\n",
    "The objective of the agent is to\n",
    "- Compute a strategy\n",
    "- That determines which move to execute\n",
    "- In the current position or in any reachable position\n",
    "\n",
    "The performance measure is then to maximize the utility.\n",
    "\n",
    "## Definition\n",
    "\n",
    "A game is a 7-tuple $\\mathcal{S} = \\langle S, A, T, s_I, S_G, utility, player \\rangle$ with\n",
    "- Finite set of positions $S$\n",
    "- Finite set of moves $A$\n",
    "- Deterministic transition relation $T \\subseteq S \\times A \\times S$\n",
    "- Initial positions $s_I \\in S$\n",
    "- Set of terminal positions $S_G \\subseteq S$\n",
    "- Utility function $utility: S_G \\rightarrow \\mathbb{R}$\n",
    "- Player function $player: S \\textbackslash S_G \\rightarrow \\{MAX, MIN\\}$\n",
    "\n",
    "## Strategie\n",
    "\n",
    "Let $\\mathcal{S} = \\langle S, A, T, s_I, S_G, utility, player \\rangle$ be a game and let $S_{MAX} = \\{s \\in S | player(s) = MAX\\}$. A partial strategy for player MAX is a function\n",
    "\n",
    "$$\n",
    "\\pi: S'_{MAX} \\mapsto A\n",
    "$$\n",
    "\n",
    "with $S'_{MAX} \\subseteq S_{MAX}$ and $\\pi(s) = a$ implies that $a$ is applicable in $s$. If $S'_{MAX} = S_{MAX}$, then $\\pi$ is called a total strategy (or strategy).\n",
    "\n",
    "We consider approaches that must be tailored to a specific board game for good performance, e.g., by using a suitable evaluation function.\n",
    "\n",
    "## Algorithms\n",
    "\n",
    "Properties of a good algorithm for board games is\n",
    "- Look ahead as far as possible (deep search)\n",
    "- Consider only interesting parts of the game tree (selective search, analogously to heuristic search algorithms)\n",
    "- Evaluate current position as accurately as possible (evaluation function, analogously to heuristics)"
   ],
   "id": "50ac2717a2a4e3c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Minimax Search\n",
    "\n",
    "Idea\n",
    "- DFS in game tree\n",
    "- Determine utility value of terminal position with utility function\n",
    "- Strategy: action that maximizes utility value (minimax decision)\n",
    "- Compute utility value of inner nodes from below to above through the tree:\n",
    "    - MIN's turn: utility value is minimum of utility values of children\n",
    "    - MAX's turn: utility value is maximum of utility values of children"
   ],
   "id": "5ac158139d4b54fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "function minimax(p)\n",
    "\n",
    "if p is terminal position:\n",
    "\n",
    "- return $\\langle utility(p), none \\rangle$\n",
    "\n",
    "best_move = none\n",
    "\n",
    "if player(p) = MAX:\n",
    "\n",
    "- v = $-\\infty$\n",
    "\n",
    "else:\n",
    "\n",
    "- v = $\\infty$\n",
    "\n",
    "for each $\\langle move, p' \\rangle \\in succ(p)$:\n",
    "- $\\langle v', best\\_move\\rangle = minimax(p)$\n",
    "- if (player(p) = MAX and $v'>v$) or (player(p) = MIN and $v' < v$):\n",
    "    - $v = v'$\n",
    "    - best_move = move\n",
    "\n",
    "return $\\langle v, best\\_move \\rangle$"
   ],
   "id": "3b389a1b4ea3f71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Minimax is the simplest search algorithm for games. It yields a optimal strategy (in game theoretic sence, i.e., under the assumption that the opponent plays perfectly)\n",
    "MAX obtains at least the utility value computed for the root, no matter how MIN plays.\n",
    "If MIN plays perfectly, MAX obtains exactly the computed value.\n",
    "\n",
    "if the size of the game tree is too big for minimax, an alternative would be alpha-beta search."
   ],
   "id": "5664288a1af290bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluation Functions\n",
    "\n",
    "Let $\\mathcal{S}$ be a game with set of positions $S$. An evaluation function for $\\mathcal{S}$ is a function\n",
    "\n",
    "$$\n",
    "h:S \\rightarrow \\mathbb{R}\n",
    "$$\n",
    "\n",
    "which assigns a real-valued number to each position $s \\in S$\n",
    "\n",
    "Due to the game tree being too big, we search only up to a predefined depth. If this depth is reached, we estimate the utility value according to heuristic criteria. High values should relate to high \"winning chances\", and at the same time, the evaluation function should be efficiently computable in order to be able to search deeply.\n",
    "\n",
    "### Linear\n",
    "\n",
    "Expert knowledge is often represented with weighted linear functions:\n",
    "\n",
    "$$\n",
    "h(s) = w_0 + w_1 f_1(s) + ... + w_n f_n(s)\n",
    "$$\n",
    "\n",
    "where $w_i$ are weights and $f_i$ are features.\n",
    "\n",
    "This assumes that feature contributions are mutually independant. Features are usually provided by human expers. Weights are provided by human expers or learned automatically.\n",
    "\n",
    "Alternative: Evaluation function based on neural networks\n",
    "- Value network takes position features as input (usually provided by human experts)\n",
    "- And outputs utility value prediction\n",
    "- Weights of network learned automatically\n",
    "\n",
    "- Objective: Search as deeply as possible withing a given time\n",
    "- Problem: Search time difficult to predict\n",
    "- Solution: Iterative deepening\n",
    "    - Sequence of searches of increasing depth\n",
    "    - Time expires: Return result of previously finished search\n",
    "    - Overhead acceptable\n",
    "- Refinement: Search deeped in turbulent states -> quiescence search"
   ],
   "id": "8512cef4e71f14e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
