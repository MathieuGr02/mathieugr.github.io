{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Combinatorial Optmization\n",
    "\n",
    "In CO, similair to our state space searching, we have to find an action sequence from initial to goal state. Here there are no actions or transitions and we don't search for a path, but rather for a configuration with low cost / high quality.\n",
    "\n",
    "## Definition\n",
    "\n",
    "A combinatorial optimization problem (COP) is given by a tuple $\\langle C, S, opt, v \\rangle$ consisting of \n",
    "\n",
    "- A finite set of (solution) candidates $C$\n",
    "- A finite set of solutions $S \\subseteq C$\n",
    "- An objective sense $opt \\in \\{min,max\\}$\n",
    "- An objective function $v:S \\rightarrow \\mathbb{R}$\n",
    "\n",
    "Let $\\mathcal{O} = \\langle C, s, opt, v \\rangle$ be a COP.\n",
    "The optimal solution quality $v^*$ of $\\mathcal{O}$ is defined as \n",
    "\n",
    "$$\n",
    "v^* = \n",
    "\\begin{cases}\n",
    "    \\min_{c \\in S} v(c) \\qquad \\text{if } opt = \\min\\\\\n",
    "    \\max_{c \\in S} v(c) \\qquad \\text{if } opt = \\max\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "A solution is called optimal if $v(s) = v^*$.\n",
    "\n",
    "We want to find a solution of good (ideally, optimal) quality for a combinatorial optimization problem $\\mathcal{O}$ or prove that no solutions exists.\n",
    "\n",
    "In CO problems we have \n",
    "- Search Aspect: Among all candidates $C$, find a solution from set $S$.\n",
    "- Optimization Aspect: Among all solutions in $S$, find one of high quality"
   ],
   "id": "eb2e0c4373f0665a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Local Search: Hill Climbing\n",
    "\n",
    "The main ideas of heuristic search are applicable for COPs. As there are no actions in the COP, we can choose candidates which we consider neighbours. We use a heuristic $h$ to estimate the quality of candidates.\n",
    "- For optimization we use $v$ itself\n",
    "- For search we use a distance estimation to the closest solution\n"
   ],
   "id": "93a263ca0d07b01c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Maximization\n",
    "current := a random candidate\n",
    "repeat:\n",
    "    next := a neighbour of current with maximum h value\n",
    "    if h(next) <= h(current):\n",
    "        return current\n",
    "    current := next"
   ],
   "id": "35d8f358b05d13ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The problem with local search is that it may get stuck in a local optima or plateaus. Remedies for this problem are\n",
    "- Allow stagnation (steps without improvement)\n",
    "- Include random aspects in the search neighborhood\n",
    "- Sometimes make random steps\n",
    "- BFS for better candidate\n",
    "- Restarts (with new initial random candidate)"
   ],
   "id": "e2565dcb174202d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulated annealing\n",
    "\n",
    "Simulated annealing is a local search algorithm that systematically injects noise, beginning with high noise, then lowering it over time.\n",
    "- Walk with fixed number of steps $N$\n",
    "- Initially it is hot and then walk is mostly random\n",
    "- Over time the temperature drops\n",
    "- As it gets colder, moves to worse neighbors become less likely"
   ],
   "id": "d81a52b697e1e77e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "curr := a random candidate\n",
    "best := None\n",
    "for each t in [1,...,N]:\n",
    "    if is_solution(curr) and (best is None or v(curr) > v(best)):\n",
    "        best := curr\n",
    "    T := schedule(t)\n",
    "    next := a random neighbor of curr\n",
    "    dE = h(next) - h(curr)\n",
    "    if dE >= 0 or with probability e^(dE / T):\n",
    "        curr := next\n",
    "return best"
   ],
   "id": "bfa1c0a980c426bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generic Algorithms\n",
    "\n",
    "Genetic algorithms are based of the idea that evolution often finds the best solutions. Thus we simulate evolution by selection, crossover and mutation of individuals.\n",
    "\n",
    "We encode each candidate as a string of symbols (genome). We define a fitness function which evaluates the strength of each candidate. We then initialize a population of size $k$ and let them evolve."
   ],
   "id": "b707faf0690fa955"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
