{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: Maximal Entropy\n",
    "layout: collection\n",
    "permalink: /Computational-Biology/Maximal-Entropy\n",
    "collection: Computational-Biology\n",
    "mathjax: true\n",
    "toc: true\n",
    "categories:\n",
    "  - study\n",
    "tags:\n",
    "  - mathematics\n",
    "  - statistics\n",
    "---"
   ],
   "id": "5e5b02100882fe03"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mx\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T15:01:02.943600Z",
     "start_time": "2024-05-14T15:01:02.076384Z"
    }
   },
   "id": "57f7642009d0d3fd",
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Laplace's Method\n",
    "\n",
    "Assume we are estimating a single parameter $\\mu$, and given our data $ \\mathcal{D}$ we hav calculated a posterior distribution $ \\mathbb{P}(\\mu | \\mathcal{D})$. Because we may want to integrate the posterior over some area, because the posterior can be a complicated function to integrate, if the posterior has a single peak, we can estimate it by expanding the logarithm of the posterior around the peak.\n",
    "\n",
    "Let $\\mu_*$ be the mode of the distribution, thus the peak of $ \\mathbb{P}(\\mu | \\mathcal{D})$. \n",
    "We definde $L(\\mu) = \\log \\mathbb{P}(\\mu |\\mathcal{D)$. Expanding this around $\\mu_*$ with the taylor expansion gives us \n",
    "\n",
    "$$\n",
    "L(\\mu) \n",
    "\\approx \n",
    "L(\\mu_*) + \n",
    "\\frac{\\partial}{\\partial \\mu} L(\\mu) \\Bigr|_{\\mu = \\mu_*} (\\mu - \\mu_*)+\n",
    "\\frac{1}{2} \\frac{\\partial^2}{\\partial \\mu^2} L(\\mu) \\Bigr|_{\\mu = \\mu_*} (\\mu - \\mu_*)^2 + ...\n",
    "$$\n",
    "We only take the terms up to the second derivative as a good enough approximation. Because then $\\frac{\\partial}{\\partial \\mu} L(\\mu) \\Bigr|_{\\mu = \\mu_*} = 0$, because at $\\mu_*$ the posterior has a maxima, we get \n",
    "\n",
    "$$\n",
    "L(\\mu) \n",
    "\\approx \n",
    "L(\\mu_*) + \\frac{1}{2} L''(\\mu_*) (\\mu - \\mu_*)^2\n",
    "$$\n",
    "\n",
    "Then setting $L''(\\mu_*) = \\frac{1}{\\sigma^2}$ and taking the exponent we get a gaussian:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\mu | \\mathcal{D}) = e^{L(\\mu)} \\approx e^{L(\\mu_*)} e^{ - \\frac{(\\mu - \\mu_*)}{2 \\sigma^2}}\n",
    "$$\n",
    "\n",
    "Assume now that we have n parameters $ \\mathbf{\\alpha} = (\\alpha_1, \\alpha_2, ..., \\alpha_n)$ and have a likelihood function $ \\mathbf{P}(\\mathcal{D} | \\mathbf{\\alpha})$. \n",
    "Using a uniform prior we get the posterior $ \\mathbb{P}(\\mathbf{\\alpha} | \\mathcal{D}) \\propto \\mathbf{P}(\\mathcal{D} | \\mathbf{\\alpha})$. The value $ \\mathbf{\\alpha}^*$ then maximizes the posterior.\n",
    "\n",
    "Expanding then around the logarithm we get\n",
    "\n",
    "$$\n",
    "\\log \\mathbb{P}(\\mathbf{\\alpha} | \\mathcal{D}) \n",
    "= \n",
    "\\log \\mathbb{P}(\\mathbf{\\alpha}^* | \\mathcal{D}) +\n",
    "\\sum_{i} (\\alpha_i - \\alpha_i^*) \\frac{\\partial \\log \\mathbb{P}(\\mathbf{\\alpha} | \\mathcal{D})}{\\partial \\alpha_i } \\Bigr|_{\\mathbf{\\alpha} = \\mathbf{\\alpha}^*} + \n",
    "\\sum_{i,j} (\\alpha_i - \\alpha_i^*) (\\alpha_j - \\alpha_j^*)  \\frac{\\partial^2 \\log \\mathbb{P}(\\mathbf{\\alpha}^2 | \\mathcal{D})}{\\partial \\alpha_i } \\Bigr|_{\\mathbf{\\alpha} = \\mathbf{\\alpha}^*} + ...\n",
    "$$ \n",
    "\n",
    "Again the first term vanishes because of the maxima at $ \\mathbf{\\alpha}^*$. The second derivate gives the so called hessian matrix.\n",
    "\n",
    "$$\n",
    "H_{ij} = \\frac{\\partial \\log \\mathbb{P}(\\mathbf{\\alpha} | \\mathcal{D})}{\\partial \\alpha_i \\alpha_j} \\Bigr|_{\\mathbf{\\alpha}=\\mathbf{\\alpha}^*}\n",
    "$$\n",
    "\n",
    "If we set $B_{ij} = -H_{ij}$ we get the approximated posterior by a multivariate gaussian\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\mathbf{\\alpha} | \\mathcal{D}) \\propto \\exp \\left( - \\frac{1}{2} \\sum_{i,j}(\\alpha_i - \\alpha_i^*) B_{ij} (\\alpha_j - \\alpha_j^*) \\right)\n",
    "$$\n",
    "\n",
    "The covariance matrix is then given by the inverse of the hessian. If now integrate all parameters but one, the marginal distribution again is a gaussian with variance $\\sigma^2_i = B_{ij}^{-1}$:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\alpha_i | \\mathcal{D}) \\propto \\exp \\left( -\\frac{1}{2} \\frac{(\\alpha_i - \\alpha_i^*)^2}{B_{ij}^{-1} \\right)\n",
    "$$"
   ],
   "id": "5888ae09cc2c2092"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Entropy\n",
    "\n",
    "Assume we have $N$ genes in total, where each gene can have $m=0,1,2,...,$ mRNA copies in a given cell. \n",
    "On average, a gene has $\\bar{m}$ mRNAs per cell, i.e. there are $M=\\bar{m}N$ mRNAs per cell. \n",
    "We now would like to know, what is the probability $ \\mathbb{P}(m | I)$ that one particular gene has $m$ mRNAs in the cell.\n",
    "\n",
    "1. Standard way\n",
    "\n",
    "For each gene $g$ we specify the number $m_g$ of mRNAs that it has in the cell, i.e. the mutually exclusive and exhaustive possibilities are vectors $ \\mathbf{m} = (m_1, m_2, ... , m_N)$. We can then incorporate our prior information that among these potentially possible states, our information $I$ specifies that only those states have nonzero probability for which we have:\n",
    "\n",
    "$$\n",
    "M(\\mathbf{m}) = \\sum_{g=1}^{N} m_g = M = N \\bar{m}\n",
    "$$\n",
    "\n",
    "This we have a uniform prior which restricts our space to the space which has the previous given property\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\mathbf{m} | I) = \\frac{\\delta(M (\\mathbf{m}) - N \\bar{m})}{\\sum_{\\mathbf{m}'} \\delta(M (\\mathbf{m}') - N \\bar{m})}\n",
    "$$\n",
    "\n",
    "and for a single gene we have\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(m_g = m | I) = \\frac{\\sum_{\\mathbf{m}} \\delta(M(\\mathbf{m}) - N \\bar{m}) \\delta(m_g - m))}{\\sum_{\\mathbf{m}'} \\delta(M (\\mathbf{m}') - N \\bar{m})}\n",
    "$$\n",
    "\n",
    "For large N these calculations become difficult for large N, which is why we look at an approximate.\n",
    "Instead of looking at th number of mRNAs $m_g$ that each gene $g$ has, we look at the vector with the number of genes that have precisely $m$ mRNA copies $ \\mathbf{n} = (n_0, n_1, n_2, ..., n_M)$, which counts how many genes there are with 0 mRNA ($n_0$), with 1 mRNA ($n_1$) etc. \n",
    "For a given vector $ \\mathbf{n}$ there are many vectors $ \\mathbf{m}$. \n",
    "Let then $W(\\mathbf{n})$ denote the number of vectors $ \\mathbf{m}$ that all havce the same count vector $ \\mathbf{n}$.\n",
    "The numbers  $W(\\mathbf{n})$ are given by the multinomial coefficients.\n",
    "\n",
    "$$\n",
    "W(\\mathbf{n}) = \\frac{N!}{n_0 ! n_1 ! ... n_M!}\n",
    "$$\n",
    "With our constraint $M( \\mathbf{n}) = \\sum_{m=1}^{\\infty} mn_m = M = N \\bar{m}$.Then our probability distribution becomes\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\mathbf{n} | I) = \\frac{W(\\mathbf{n}) \\delta(M(\\mathbf{n}) - N\\bar{m})}{\\sum_{\\mathbf{n}'} W(\\mathbf{n}')\\delta(M(\\mathbf{n'}) - N\\bar{m})}\n",
    "$$\n",
    "\n",
    "Using now the stirling approximation for factorials $n! \\approx n^n e^{-n}$:\n",
    "\n",
    "$$\n",
    "\\log W( \\mathbf{n}) \n",
    "= \n",
    "N \\log N - N - \\sum_{m=0}^{\\infty} \\left( n_m \\log n_m - n_m \\right) \n",
    "= - \\sum_{m= 0}^{\\infty} \\left( n_m \\log(n_m) - n_m \\log N \\right)\n",
    "= - N \\sum_{m=0}^{\\infty} \\frac{n_m}{ N} \\log \\left( \\frac{n_m}{N}  \\right) \n",
    "$$\n",
    "\n",
    "With $f_m = \\frac{n_m}{N}$, we get the entropy function $H[\\mathbf{f}] = - \\sum_m f_m \\log f_m$. Thus we get that $W(\\mathbf{f}) = e^{N H [\\mathbf{f} ]} $ and $ \\mathbb{P}(\\mathbf{f} | I) \\propto e^{NH [\\mathbf{f} ]} \\delta (m(\\mathbf{f} | - \\bar{m}))$ with $m(\\mathbf{f} ) = \\sum_{m} mf_m$  \n",
    "For $N \\rightarrow \\infty$ we gat the probability distribution is dominated by the entropy of the vector $ \\mathbf{f}_* $ which has the highest entropy. "
   ],
   "id": "d944ac4e3dd2c398"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To now find the vector $ \\mathbf{f}_* $ which maximizes the entropy, we use the lagrange multipliers. Denote $ \\mathbf{\\nu} $ as vector in the dimension $M + 1$ suscht that if we move away from $ \\mathbf{f}_* $ in the direction of $ \\mathbf{\\nu} $ then the average $m (\\mathbf{f} )$ is unchanged. Our optimum is characterized by $ \\mathbf{\\nu} \\nabla H[ \\mathbf{f} ] = 0 \\ \\forall \\mathbf{\\nu}, \\ \\mathbf{\\nu} \\nabla m (\\mathbf{f} ) = 0$\n",
    "\n",
    "Because by the multivariate taylor expansion we get :\n",
    "\n",
    "$$\n",
    "m(\\mathbf{f} + \\epsilon \\mathbf{\\nu} ) \n",
    "= \n",
    "m(\\mathbf{f}) + \\epsilon \\sum_i \\nu_i \\frac{\\partial m(\\mathbf{f})}{\\partial f_i}  \n",
    "=\n",
    "m( \\mathbf{f}) + \\epsilon \\mathbf{\\nu} \\nabla m ( \\mathbf{f})   \n",
    "$$\n",
    "\n",
    "Thus then if $ \\mathbf{\\nu} \\nabla m( \\mathbf{f} ) = 0 $ it follows that $m( \\mathbf{f} + \\epsilon \\mathbf{\\nu}) = m ( \\mathbf{f} ) $, meaning that it is constant in the direction of  $ \\mathbf{\\nu} $.\n",
    "\n",
    "Then the same for our entropy function\n",
    "\n",
    "$$\n",
    "H[ \\mathbf{f} + \\epsilon \\mathbf{\\nu}  ] = H[ \\mathbf{f} ] + \\epsilon \\mathbf{\\nu} \\nabla H[\\mathbf{f} ]\n",
    "$$\n",
    "Because we want our optimum, $ \\mathbf{\\nu} \\nabla H[ \\mathbf{f} ] = 0 \\ \\forall \\mathbf{\\nu} $ with $ \\mathbf{\\nu} \\nabla m( \\mathbf{f} ) = 0 $. If we definde $X[\\mathbf{f}] = H[\\mathbf{f}] + \\lambda m(\\mathbf{f})$ then $\\nabla X[\\mathbf{f] = 0 \\Leftrightarrow \\mathbf{\\nu} \\nabla H[\\mathbf{f}] = 0 $ when $ \\mathbf{\\nu} \\nabla m(\\mathbf{f}) = 0 $.  \n",
    "When $\\nabla X[\\mathbf{f}] = 0 \\Leftrightarrow \\nabla H[\\mathbf{f}] = - \\lambda \\nabla m(\\mathbf{f})$. Thus at $ \\mathbf{f}_* $ we have that for any direction $ \\mathbf{\\nu} $  Here we get \n",
    "\n",
    "$$ \n",
    "\\frac{\\partial X( \\mathbf{f}) }{\\partial f} =\\frac{\\partial }{\\partial f} \\left( - \\sum_m f_m \\log f_m + \\sum_{m} mf_m \\right) = - 1 - \\log(f_m) + \\lambda m   = 0 \\\\\n",
    "\\Rightarrow f_m = e^{-1 + \\lambda m }\n",
    "$$\n",
    "\n",
    "If we add another constraint that $C(\\mathbf{f}) = \\sum_m f_m = 1 $ we get $X(\\mathbf{f} ) = H[\\mathbf{f}] + \\lambda_1 m(\\mathbf{f}) + \\lambda_2 C(\\mathbf{f})$ which then gives us $f_m = e^{\\lambda_1 m + \\lambda_2 - 1}$\n",
    "\n",
    "This can be generalized to \n",
    "\n",
    "$$\n",
    "X(\\mathbf{f}) = H(\\mathbf{f}) + \\sum_{k=1}^n \\lambda_k C_k (\\mathbf{f})   \n",
    "$$\n",
    "\n",
    "Looking back, because we get that $f_m = e^{\\lambda_1 m + \\lambda_2 - 1}$ we set our $\\lambda_2$ by demanding that $\\sum_m f_m = 1$\n",
    "\n",
    "$$\n",
    "\\sum_m f_m = 1 \\Rightarrow \\frac{e^{\\lambda_1 m}}{\\sum_{m'} e^{\\lambda_1 m'}} = e^{\\lambda_1 m} (1 - e^{\\lambda_1})  \n",
    "$$\n",
    "\n",
    "for $\\lambda_1$ we demand that $\\sum_m m f_m = \\bar{m} = \\sum_m m e^{\\lambda_1 m} (1 - e^{\\lambda_1})$.\n",
    "For this we introduce the partition function \n",
    "\n",
    "$$\n",
    "Z(\\lambda) = \\sum_m e^{\\lambda m} = \\frac{1}{1 - e^{\\lambda}} \n",
    "$$\n",
    "\n",
    "Which then gives $\\langle m \\rangle = \\frac{d \\log Z(\\lambda)}{d \\lambda} = \\frac{e^{\\lambda}}{1 - e^{\\lambda}} = \\bar{m} \\Rightarrow \\lambda = \\log \\left( \\frac{\\bar{m}}{\\bar{m} + 1}  \\right)  $.\n",
    "Thus in the end we get our probability of finding a gene having m mRNAs  is $ \\mathbb{P}(m | I) = f_m  = \\frac{1}{\\bar{m} + 1} \\left( \\frac{\\bar{m}}{\\bar{m} + 1}  \\right)^m $"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f576aacbeeebbc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Information theory\n",
    "\n",
    "Consider a topic X in which the reveiver has information I. The state of this knowledge is represented by a probability distribution $ \\mathbb{P}(X_i | I) $. Upon receiving a message this state of knowledge is updated $I \\rightarrow I'$.\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(X_1 | I), \\mathbb{P}(X_2 | I),... \\xrightarrow[I \\rightarrow I']{} \\mathbb{P}(X_1 | I'), \\mathbb{P}(X_2 | I'),... \n",
    "$$\n",
    "\n",
    "To quantify / measure how much information the message contained, we need a measure of how much uncertainty is associated with the distribution $ \\mathbb{P}(X_i | I) $ and $ \\mathbb{P}(X_i | I') $. The information in the message is then simply the amount by which this uncertainty was reduced.\n",
    "\n",
    "Axioms:\n",
    "\n",
    "1. There exist a funtion $H[\\mathbb{P} ]$ that assigns a real number to each probability distribution $ \\mathbb{P} $ which quantifie the ignorance / uncertainty / not-knowing associated with that probability distribution.\n",
    "2. It is a continous function of it's arguments\n",
    "3. Fr the uniform distribution over n variables, the function $h(n) = H \\left( \\frac{1}{n}, \\frac{1}{n}, ..., \\frac{1}{n} \\right)$ should increase with n.\n",
    "4. It should be consistent in that, if it can be calculated in multiple ways, it always gives the same result. \n",
    "\n",
    "Assuming a uniform distribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baf14a3390eb1ba3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cae26a3cf94defa3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
